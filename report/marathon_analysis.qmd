---
title: "Marathon Race Time Prediction"
author: "Kexin Shi"
date: "`r Sys.Date()`"
format:
    html:
        toc: true
        toc-depth: 2
        embed-resources: true
    pdf:
        toc: true
        toc-depth: 3
        embed-resources: true
        documentclass: scrartcl
        header-includes:
          - \usepackage{float}
bibliography: references.bib
editor: source
---

```{r, include=FALSE}
#| include: false
#| echo: false

options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("here")
install.packages("tidymodels")
library(tidyverse)
library(fs)
library(here)
library(tidymodels)
library(testthat)
library(knitr)
```
# Summary

Over the last ten years, marathon running has become a popular physical activity around the world. This study aims to investigate the relationship between marathon runners' maximum distance ran per week during race training and their race time. We modeled a simple linear regression to predict marathon times based on their training patterns and tested on the model with the test dataset. By having this analysis, it helps marathon lovers to gain insights into how training volume influences race performance and to better prepare the race.


# Introduction

Over the last ten years, marathon running has become a popular physical activity around the world @marathon. It is commonly known as a high-level endurance exercise that requires the runners to have dedicated training @kaufmann2020inflammation. The maximum distance ran per week during race training is a key metric that marathon lovers would care about and is a key reference to predict which athletes will perform better than others. Thus, this study will investigate how the maximum distance ran per week during race training will predict the time it takes a runner to finish the race. Specifically, we want to answer the question: What predicts which athletes will perform better than others? How the maximum distance ran per week (in miles) during race training predicts the time it takes a runner to finish the race? This study uses the dataset from a a public dataset on GitHub, containing 13 variables about runners, such as age, bmi, maximum training distance per week (max, in miles) and actual marathon race time (time_hrs, in hours) and so on.

```{r, include=FALSE}
#| include: false
#| echo: false
# download and save data

if (!fs::dir_exists(here::here("data"))) {
  fs::dir_create(here::here("data"))
}

if (!fs::file_exists(here::here("data/marathon.csv"))) {
  url <- "https://raw.githubusercontent.com/UBC-DSCI/dsci-100-student/refs/heads/master/materials/R/worksheet_regression2/data/marathon.csv"
  marathon <- readr::read_csv(url)
  readr::write_csv(marathon, here::here("data/marathon.csv"))
}
```


```{r}
#| include: false
#| echo: false
# read saved data
marathon <- readr::read_csv(here::here("data/marathon.csv"))
```

```{r, include=FALSE}
## Data Validation Check
### Correct Data File Format
#| include: false
#| echo: false
if (!inherits(marathon, "data.frame")) {
  stop("The data file is not in the correct format. Expected a CSV to be read as a data frame.")
}

empty_rows <- apply(marathon, 1, function(row) all(is.na(row)))
if (any(empty_rows)) {
  warning("There are completely empty observations. Consider removing these rows.")
  marathon <- marathon[!empty_rows, ]
}

if (any(duplicated(marathon))) {
  warning("There are duplicate observations. Removing them now.")
  marathon <- marathon[!duplicated(marathon), ]
}
```

# EDA
We want to predict race time (in hours) (time_hrs) given a particular value of
maximum distance ran per week (in miles) during race training (max).
With this subset, we can plot a scatterplot to assess the relationship between these two variables.

![Scatterplot of Sub Dataset Maximum Distance Ran per Week vs. Race Time](../results/subset_scatterplot_maxDistance_racetime.png){#fig-1 width="65%" fig-pos="H"}
```{r}
#| include: false
#| echo: false
set.seed(2000)

marathon_50 <- marathon |>
  dplyr::sample_n(50)

subset_scatterplot_maxDistance_racetime <- marathon_50 |>
  ggplot(aes(x = max, y = time_hrs)) +
  geom_point(alpha = 0.5) +
  xlab("Maximum Distance Ran per\nWeek During Training (miles)") +
  ylab("Race Time (hours)") +
  theme(text = element_text(size = 20))
subset_scatterplot_maxDistance_racetime
```

Here's the full dataset of values.

![Scatterplot of Full Dataset Maximum Distance Ran per Week vs. Race Time](../results/full_scatterplot_maxDistance_racetime.png){#fig-2 width="65%" fig-pos="H"}
```{r}
#| include: false
#| echo: false
full_scatterplot_maxDistance_racetime <- ggplot(marathon, aes(x = max, y = time_hrs)) +
  geom_point(alpha = 0.5) +
  xlab("Maximum Distance Ran per\nWeek During Training (miles)") +
  ylab("Race Time (hours)") +
  theme(text = element_text(size = ))
full_scatterplot_maxDistance_racetime
```

# Method

From the plots shown in the EDA section, we observed an approximate negatively correlated relationship between maximum weekly distance and marathon race time. To further explore it, we will analyze the data using simple linear regression to assess the relationship between maximum weekly distance and marathon race time. We assume
We will first split the dataset into the training and testing datasets, using 75% of the original data as the training data. The training set was used to fit the model, while the test set was used for performance evaluation. We will predict on the test dataset with the model to evaluate the model's performance on unseen data. In the strata argument of the initial_split function, we will use the variable we are trying to predict. RMSPE is the main metric that we will use to evaluate the model performance, which stands for Root Mean Squared Error. Although scoring multiple models with either MSE or RMSE would yield the same ranking of the models, communicating erros in RMSE are often easier to understand.


# Analysis
## Training Data

```{r}
#| include: false
#| echo: false
set.seed(2000)

marathon_split <- rsample::initial_split(marathon, prop = 0.75, strata = time_hrs)
marathon_training <- rsample::training(marathon_split)
marathon_testing <- rsample::testing(marathon_split)
```

![Scatterplot of Training Dataset Maximum Distance Ran per Week vs. Race Time](../results/training_scatterplot.png){#fig-ts width="65%" fig-pos="H"}

We can look at @fig-ts to assess the relationship between race time (time_hrs)
and maximum distance ran per week during training (max)
using only the observations in the training dataset.

```{r}
#| include: false
#| echo: false
training_scatterplot <- marathon_training |>
  ggplot(aes(x = max, y = time_hrs)) +
  geom_point(alpha = 0.25, size = 2) +
  xlab("Maximum Distance Ran per \n Week During Training (miles)") +
  ylab("Race Time (hours)") +
  theme(text = element_text(size = 20))
training_scatterplot
```

## Linear Regession

Now that we have our training data,
the next step is to build a linear regression model specification.

```{r}
#| include: false
#| echo: false
lm_spec <- parsnip::linear_reg() |>
  parsnip::set_engine("lm") |>
  parsnip::set_mode("regression")

lm_spec
```

After we have created our linear regression model specification,
the next step is to create a recipe,
establish a workflow analysis and fit our simple linear regression model.

```{r}
#| include: false
#| echo: false
lm_recipe <- recipes::recipe(time_hrs ~ max, data = marathon_training)

lm_fit <- workflows::workflow() |>
  workflows::add_recipe(lm_recipe) |>
  workflows::add_model(lm_spec) |>
  parsnip::fit(data = marathon_training)

```

# Results

Now, let's visualize the model predictions as a straight line overlaid on the training data.

```{r}
#| include: false
#| echo: false
marathon_preds <- lm_fit |>
  predict(marathon_training) |>
  dplyr::bind_cols(marathon_training)

```
![The Linear Regression of Maximum Distance Ran per Week And Race Time On Training Set](../results/training_prediction_plot.png){#fig-4 width="65%" fig-pos="H"}
```{r}
#| include: false
#| echo: false
training_prediction_plot <- marathon_preds |>
  ggplot(aes(x = max, y = time_hrs)) +
  geom_point(alpha = 0.4) +
  geom_line(
    mapping = aes(x = max, y = .pred), 
    color = "blue") +
  xlab("Maximum Distance Ran per \n Week During Training (mi)") +
  ylab("Race Time (hours)") +
  theme(text = element_text(size = 20))
training_prediction_plot
```

## Model Performance

We can look at our model performance by looking at the RMSE on the test data.

```{r message=FALSE, echo=FALSE}
#| label: tbl-rmse
#| tbl-cap: "Linear Regression ON RMSE Metric"

lm_test_results <- lm_fit |>
  predict(marathon_testing) |>
  dplyr::bind_cols(marathon_testing) |>
  yardstick::metrics(truth = time_hrs, estimate = .pred)

lm_rmse <- lm_test_results |>
  dplyr::filter(.metric == 'rmse') |>
  dplyr::select(.estimate) |>
  dplyr::pull()
kable(lm_rmse)
```

The @tbl-rmse stands for the Root Mean Squared Prediction Error, which is a scoring metric that reflects how right/wrong each prediction is. It measures the distance of the prediction from the actual values on the test data. Lower RMSPE values indicate better predictive performance, meaning that the model's predicted values are close to the actual observed values @TARAJI2017298. In our case, the RMSPE represents the average error in predicting marathon race time (in hours) for the runners. From the result of 0.5504829, This means that, our simple linear regression model's predictions deviate from the actual race times by approximately 0.55 hours on average. 

## Prediction on test data

Visualize the model predictions as a straight line overlaid on the test data

![The Linear Regression Model Prediction Over Test Data](../results/test_prediction_plot.png){#fig5 width="65%" fig-pos="H"}
```{r}
#| include: false
#| echo: false
test_preds <- lm_fit |>
  predict(marathon_testing) |>
  dplyr::bind_cols(marathon_testing)

test_prediction_plot <- test_preds |>
  ggplot(aes(x = max, y = time_hrs)) +
  geom_point(alpha = 0.4) +
  geom_line(
    mapping = aes(x = max, y = .pred), 
    color = "blue") +
  xlab("Maximum Distance Ran per \n Week During Training (mi)") +
  ylab("Race Time (hours)") +
  theme(text = element_text(size = 20))

test_prediction_plot
```
```{r message=FALSE, echo=FALSE}
#| label: tbl-lrcoe
#| tbl-cap: "Linear Regression Results"
lm_coefficients <- broom::tidy(lm_fit)
kable(lm_coefficients)
```

## Interpretation

By having @tbl-lrcoe, the slope coefficient is -0.0215, which shows a negative relationship between the maximum distance ran per week and the race time. As the maximum distance ran increases by every additional mile per week, the race time will decrease by 0.0215 hours. It shows that adding more training distance per week is beneficial for improving marathon performance. The intercept is 4.88, wich represents that when the maximum distance ran per week (max) is zero miles, the predicted race time is 4.88 hours. Although this scenario is unrealistic, it serves as the baseline value from which changes in race time are predicted based on the training distance. These coefficients with p-value of 6.03e-64 and 0 (less than 0.05) are statistically significant, meaning there is strong evidence that increasing the training mileage leads to faster marathon times.

If we want to manually calculate the marathon time, the formula will be like $times_{hrs} = 4.88 - 0.0215 \times max$, where $times_{hrs}$ is the race time and the $max$ is the maximum distance (in miles) ran per week during training.

# Discussion

However, there are several limitations of the model. As we are trying to find what predicts which athletes will perform better than others, other features about the runners may also be crucial to play roles in affecting the race time, such as their age, bmi. Therefore, we may need to add more features to the model to better predict the race time. Also, these features may not in a linear relationship with the race time, so using a Random Forest model to handle the complex, non-linear interactions between features may be useful.

To know whether the new model would be better than the simple linear regression or not, we can use those scoring metrics such as Mean squared error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and R-squared ($R^2$) on a test set or through cross-validation.A lower MSE, RMSE, MAE, MAPE would indicate that the new model makes more accurate predictions compared to the simple linear regression model. A higher R-squared would suggest that the model is explaining more variance in the target variable, implying better performance @kolhatkar2023regression.

# Reference